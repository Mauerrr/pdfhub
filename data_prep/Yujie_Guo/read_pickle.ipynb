{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/media/yujie/data/E2EAD/endtoenddriving')\n",
    "from navsim.common.dataclasses import AgentInput, Scene, Annotations, Lidar\n",
    "from navsim.common.enums import BoundingBoxIndex, LidarIndex\n",
    "from navsim.visualization import lidar\n",
    "\n",
    "use_ground_plane = False\n",
    "\n",
    "def _get_lidar_feature(agent_input: AgentInput) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute LiDAR feature as 2D histogram, according to Transfuser\n",
    "    :param agent_input: input dataclass\n",
    "    :return: LiDAR histogram as torch tensors\n",
    "    \"\"\"\n",
    "\n",
    "    # only consider (x,y,z) & swap axes for (N,3) numpy array\n",
    "    lidar_pc = agent_input.lidars[-1].lidar_pc[LidarIndex.POSITION].T # type: ignore\n",
    "\n",
    "    # NOTE: Code from\n",
    "    # https://github.com/autonomousvision/carla_garage/blob/main/team_code/data.py#L873\n",
    "    def splat_points(point_cloud):\n",
    "        # 256 x 256 grid\n",
    "        xbins = np.linspace(\n",
    "            -32,\n",
    "            32,\n",
    "            5,\n",
    "        )\n",
    "        ybins = np.linspace(\n",
    "            -32,\n",
    "            32,\n",
    "            5,\n",
    "        )\n",
    "        hist = np.histogramdd(point_cloud[:, :2], bins=(xbins, ybins))[0]\n",
    "        hist[hist > 5] = 5\n",
    "        overhead_splat = hist / 5\n",
    "        return overhead_splat\n",
    "\n",
    "    # Remove points above the vehicle\n",
    "    lidar_pc = lidar_pc[lidar_pc[..., 2] < 100]\n",
    "    below = lidar_pc[lidar_pc[..., 2] <= 0.2]\n",
    "    above = lidar_pc[lidar_pc[..., 2] > 0.2]\n",
    "    above_features = splat_points(above)\n",
    "    print(above_features)\n",
    "    if use_ground_plane:\n",
    "        below_features = splat_points(below)\n",
    "        features = np.stack([below_features, above_features], axis=-1)\n",
    "    else:\n",
    "        features = np.stack([above_features], axis=-1)\n",
    "    features = np.transpose(features, (2, 0, 1)).astype(np.float32)\n",
    "\n",
    "    return torch.tensor(features)\n",
    "\n",
    "from defusedxml import DTDForbidden\n",
    "import numpy as np\n",
    "\n",
    "pcd_file = \"/media/yujie/data/E2EAD/endtoenddriving/dataset/sensor_blobs/private_test_e2e/MergedPointCloud/0a0e88dc86ee34d1.pcd\"\n",
    "f = open(pcd_file, 'rb')\n",
    "# 读取pcd文件头信息\n",
    "header = \"0a0e88dc86ee34d1.pcd\"\n",
    "while True:\n",
    "    line = f.readline().decode('utf-8')\n",
    "    header += line\n",
    "    if line.startswith(\"DATA\"):\n",
    "        break\n",
    "\n",
    "# 从文件内容中读取三维坐标点云数据\n",
    "#dtype = np.dtype([('x', np.float32), ('y', np.float32), ('z', np.float32), ('intensity', np.float32),('ring', np.float32),('lidar_id', np.float32)])\n",
    "data = np.fromfile(f, dtype=np.float32)\n",
    "data = data[:30].reshape(5, 6)\n",
    "print(data)\n",
    "\n",
    "# Define your lidar data\n",
    "lidar_pc_data = data\n",
    "\n",
    "# Create a Lidar object\n",
    "lidar_ = Lidar(lidar_pc=lidar_pc_data)\n",
    "\n",
    "# Create an AgentInput instance with a list containing the lidar data\n",
    "lidar_data = [lidar_]\n",
    "agent_input = AgentInput(ego_statuses=[], cameras=[], lidars=lidar_data)\n",
    "\n",
    "# Call the _get_lidar_feature function\n",
    "lidar_feature = _get_lidar_feature(agent_input)\n",
    "\n",
    "print(lidar_feature)\n",
    "\n",
    "print(lidar_feature.size())\n",
    "\n",
    "lidar_feature_nonzero = np.nonzero(lidar_feature)\n",
    "print(lidar_feature_nonzero)\n",
    "#print(lidar_feature[0, 125:128, 125:128])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 假设你有一些点云数据和直方图的边界\n",
    "point_cloud = np.random.rand(5, 3)  # 假设点云数据是一个包含100个点的数组，每个点有3个坐标\n",
    "print(point_cloud)\n",
    "above = point_cloud[point_cloud[..., 2] > 0.2]\n",
    "print(above)\n",
    "xbins = np.linspace(0, 1, 10)  # 假设x轴的边界\n",
    "ybins = np.linspace(0, 1, 10)  # 假设y轴的边界\n",
    "\n",
    "# 使用 numpy.histogramdd 计算直方图\n",
    "hist = np.histogramdd(above[:, :2], bins=(xbins, ybins))[0]\n",
    "hist[hist > 5] = 5\n",
    "overhead_splat = hist / 5\n",
    "hist_nonzero = np.nonzero(hist)\n",
    "print(hist)\n",
    "print(hist_nonzero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "path_train = \"/media/yujie/data/E2EAD/endtoenddriving/exp/submission_lstm8_ego_state_warmup/2024.05.03.11.25.55/submission.pkl\"\n",
    "\n",
    "f = open(path_train, 'rb')\n",
    "data_train = pickle.load(f)\n",
    "# print(f\"train: {data_train[1]['log_name']}\")\n",
    "# for i in range(1, len(data_train)):\n",
    "#     if data_train[i]['log_name'] != data_train[i-1]['log_name']:\n",
    "#         print(f\"train: {data_train[i]['log_name']}\")\n",
    "#     #print(data[i]['scene_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from defusedxml import DTDForbidden\n",
    "import numpy as np\n",
    "\n",
    "pcd_file = \"/media/yujie/data/E2EAD/endtoenddriving/dataset/sensor_blobs/private_test_e2e/MergedPointCloud/0a0e88dc86ee34d1.pcd\"\n",
    "f = open(pcd_file, 'rb')\n",
    "# 读取pcd文件头信息\n",
    "header = \"0a0e88dc86ee34d1.pcd\"\n",
    "while True:\n",
    "    line = f.readline().decode('utf-8')\n",
    "    header += line\n",
    "    if line.startswith(\"DATA\"):\n",
    "        break\n",
    "\n",
    "# 从文件内容中读取三维坐标点云数据\n",
    "#dtype = np.dtype([('x', np.float32), ('y', np.float32), ('z', np.float32), ('intensity', np.float32),('ring', np.float32),('lidar_id', np.float32)])\n",
    "data = np.fromfile(f, dtype=np.float32)\n",
    "\n",
    "#print(data)  \n",
    "#data = np.fromfile(f, dtype=dtype)\n",
    "print(data[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = {'a': torch.tensor([[ 664651.3614, 3999258.5894],\n",
    "                [ 664650.9561, 3999257.7967],\n",
    "                [ 664650.6527, 3999257.2051],\n",
    "                [ 664650.4523, 3999256.8068],\n",
    "                [ 664650.3505, 3999256.6042],\n",
    "                [ 664650.3300, 3999256.5648],\n",
    "                [ 664650.3476, 3999256.5846],\n",
    "                [ 664650.3563, 3999256.5980]], dtype=torch.float64)}\n",
    "b = 'train'\n",
    "c = [a,b]\n",
    "# print(c)\n",
    "# print(c[0])\n",
    "# print(c[1])\n",
    "b = torch.randn(1, 8, 11)\n",
    "current_feature = torch.zeros(1, 1, 3)\n",
    "print(b)\n",
    "b[:, :, :3] = torch.cat((b[:, :-1, :3] - b[:, 1:, :3], current_feature), dim=1)\n",
    "print(b)\n",
    "# zero_row = torch.zeros_like(a[-1]).unsqueeze(0)\n",
    "# print(zero_row)\n",
    "# torch.cat((a[:-1] - a[1:], zero_row), dim=0)\n",
    "#b = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_val = \"/home/yujie/OpenScene/dataset/data/openscene_mini_val.pkl\"\n",
    "\n",
    "f = open(path_val, 'rb')\n",
    "data_val = pickle.load(f)\n",
    "print(f\"val: {data_val[1]['log_name']}\")\n",
    "for i in range(1, len(data_val)):\n",
    "    if data_val[i]['log_name'] != data_val[i-1]['log_name']:\n",
    "        print(f\"val: {data_val[i]['log_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "path = \"/media/yujie/data/E2EAD/endtoenddriving/dataset/navsim_logs/private_test_e2e/competition_test.pkl\"\n",
    "# /media/yujie/data/E2EAD/endtoenddriving/dataset/navsim_logs/private_test_e2e/competition_test.pkl\n",
    "f = open(path, 'rb')\n",
    "data = pickle.load(f)\n",
    "i = 10\n",
    "print(\"Path, i: \", path, i)\n",
    "print(\"Time stamp: \", data[i]['timestamp'])\n",
    "print(\"Driving command: \", data[i]['driving_command'])\n",
    "print(\"The velocity and acceleration of ego car: \", data[i]['ego_dynamic_state'])\n",
    "\n",
    "info_CAM_B0 = data[i]['cams']['CAM_B0']\n",
    "info_CAM_F0 = data[i]['cams']['CAM_F0']\n",
    "info_CAM_L0 = data[i]['cams']['CAM_L0']\n",
    "info_CAM_L1 = data[i]['cams']['CAM_L1']\n",
    "info_CAM_L2 = data[i]['cams']['CAM_L2']\n",
    "info_CAM_R0 = data[i]['cams']['CAM_R0']\n",
    "info_CAM_R1 = data[i]['cams']['CAM_R1']\n",
    "info_CAM_R2 = data[i]['cams']['CAM_R2']\n",
    "\n",
    "path_sensor = \"/media/yujie/data/E2EAD/endtoenddriving/dataset/sensor_blobs/private_test_e2e\"\n",
    "\n",
    "# 构建图像路径字典\n",
    "image_paths = {\n",
    "    'B0': info_CAM_B0['data_path'],\n",
    "    'F0': info_CAM_F0['data_path'],\n",
    "    'L0': info_CAM_L0['data_path'],\n",
    "    'L1': info_CAM_L1['data_path'],\n",
    "    'L2': info_CAM_L2['data_path'],\n",
    "    'R0': info_CAM_R0['data_path'],\n",
    "    'R1': info_CAM_R1['data_path'],\n",
    "    'R2': info_CAM_R2['data_path']\n",
    "}\n",
    "\n",
    "# 使用循环读取图像并转换为RGB格式\n",
    "images_rgb = {}\n",
    "for name, path in image_paths.items():\n",
    "    image = cv2.imread(os.path.join(path_sensor, path))\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    images_rgb[name] = image_rgb\n",
    "\n",
    "# 创建一张白图\n",
    "white_image = np.ones_like(images_rgb['F0']) * 255  # Create a white image\n",
    "\n",
    "# 显示图像\n",
    "fig, axs = plt.subplots(3, 3, figsize=(9, 9))\n",
    "\n",
    "# 左视图\n",
    "axs[0, 0].imshow(images_rgb['L0'])\n",
    "axs[0, 0].set_title('Left 0')\n",
    "axs[0, 0].axis('off')\n",
    "\n",
    "axs[1, 0].imshow(images_rgb['L1'])\n",
    "axs[1, 0].set_title('Left 1')\n",
    "axs[1, 0].axis('off')\n",
    "\n",
    "axs[2, 0].imshow(images_rgb['L2'])\n",
    "axs[2, 0].set_title('Left 2')\n",
    "axs[2, 0].axis('off')\n",
    "\n",
    "# 前视图和白图\n",
    "axs[0, 1].imshow(images_rgb['F0'])\n",
    "axs[0, 1].set_title('Front')\n",
    "axs[0, 1].axis('off')\n",
    "\n",
    "axs[1, 1].imshow(white_image, cmap='gray')\n",
    "axs[1, 1].set_title('')\n",
    "axs[1, 1].axis('off')\n",
    "\n",
    "axs[2, 1].imshow(images_rgb['B0'])\n",
    "axs[2, 1].set_title('Back')\n",
    "axs[2, 1].axis('off')\n",
    "\n",
    "# 右视图\n",
    "axs[0, 2].imshow(images_rgb['R0'])\n",
    "axs[0, 2].set_title('Right 0')\n",
    "axs[0, 2].axis('off')\n",
    "\n",
    "axs[1, 2].imshow(images_rgb['R1'])\n",
    "axs[1, 2].set_title('Right 1')\n",
    "axs[1, 2].axis('off')\n",
    "\n",
    "axs[2, 2].imshow(images_rgb['R2'])\n",
    "axs[2, 2].set_title('Right 2')\n",
    "axs[2, 2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anns\n",
    "anns_boxes = data[i]['anns']['gt_boxes'] # X = 0,_Y = 1,_Z = 2,_LENGTH = 3,_WIDTH = 4,_HEIGHT = 5,_HEADING = 6\n",
    "print(anns_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "x = tensor([[ 664754.0141, 3999465.8250],\n",
    "        [ 664754.0147, 3999465.8251],\n",
    "        [ 664754.0146, 3999465.8251],\n",
    "        [ 664754.0146, 3999465.8251],\n",
    "        [ 664754.0146, 3999465.8250],\n",
    "        [ 664754.0147, 3999465.8251],\n",
    "        [ 664754.0147, 3999465.8250],\n",
    "        [ 664754.0147, 3999465.8250],\n",
    "        [ 664754.0146, 3999465.8250],\n",
    "        [ 664754.0146, 3999465.8250],\n",
    "        [ 664754.0146, 3999465.8250],\n",
    "        [ 664754.0146, 3999465.8250],\n",
    "        [ 664754.0146, 3999465.8250],\n",
    "        [ 664754.0147, 3999465.8250],\n",
    "        [ 664754.0146, 3999465.8251],\n",
    "        [ 664754.0142, 3999465.8251]], dtype=torch.float64)\n",
    "#print(x[:-1])\n",
    "y = tensor([[[1, 2],\n",
    "             [2, 3],\n",
    "             [3, 4],\n",
    "             [4, 5]],\n",
    "            [[6, 1],\n",
    "             [7, 2],\n",
    "             [8, 3],\n",
    "             [9, 0]]], dtype=torch.float32)\n",
    "z = tensor([[[-1, 2],\n",
    "             [2, 3],\n",
    "             [3, 4],\n",
    "             [4, 5]],\n",
    "            [[-6, 1],\n",
    "             [7, 2],\n",
    "             [8, 3],\n",
    "             [9, 0]]], dtype=torch.float32)\n",
    "\n",
    "delta_mul = torch.mul(y, z)\n",
    "\n",
    "# 遍历 y 的每一行，计算累加和并填充到 delta_sum 中\n",
    "# for i in range(1, y.size(0)):\n",
    "#     delta_sum[:,:,i] = y[:,:,:i].sum(dim=0)\n",
    "delta_sum[:, 1:, :] = torch.cumsum(y[:, :-1, :], dim=1)\n",
    "\n",
    "print(delta_mul)\n",
    "print(torch.cumsum(y, dim=1))\n",
    "\n",
    "#print(x[:-1] - x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch import Tensor\n",
    "# # test\n",
    "# batch_size = 2\n",
    "# x = Tensor([[1, 2, 3, 4, 5, 6],[1, 2, 3, 4, 5, 6]])\n",
    "# print(x.size())\n",
    "# x = x.view(batch_size, -1, 2)\n",
    "# print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 24\n",
    "info_CAM_B0 = data[i]['cams']['CAM_B0']\n",
    "info_CAM_F0 = data[i]['cams']['CAM_F0']\n",
    "info_CAM_L0 = data[i]['cams']['CAM_L0']\n",
    "info_CAM_L1 = data[i]['cams']['CAM_L1']\n",
    "info_CAM_L2 = data[i]['cams']['CAM_L2']\n",
    "info_CAM_R0 = data[i]['cams']['CAM_R0']\n",
    "info_CAM_R1 = data[i]['cams']['CAM_R1']\n",
    "info_CAM_R2 = data[i]['cams']['CAM_R2']\n",
    "\n",
    "# print(data[0]['ego2global_rotation'])\n",
    "# print(data[0]['timestamp'])\n",
    "# print(data[1]['timestamp'])\n",
    "# print(data[2]['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "path_pointcloud = os.path.join(path_sensor, data[0]['lidar_path'])\n",
    "\n",
    "pointcloud = o3d.io.read_point_cloud(path_pointcloud)\n",
    "\n",
    "# 可视化点云\n",
    "o3d.visualization.draw_geometries([pointcloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['anns']['track_tokens']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
